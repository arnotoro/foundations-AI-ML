{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge/LASSO polynomial regression with linear and random sampling\n",
    "* Input variable space is constructed using random sampling/cluster pick/uniform sampling\n",
    "* Linear fit is often inadequate but higher-order polynomial fits often leads to overfitting i.e. learns spurious, flawed relationships between input and output\n",
    "* Ridge and LASSO regression are used with varying model complexity (degree of polynomial)\n",
    "* Model score is obtained on a test set and average score over a # of runs is compared for linear and random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_points = 41 # Number of points for constructing function\n",
    "x_min = 1 # Min of the range of x (feature)\n",
    "x_max = 10 # Max of the range of x (feature)\n",
    "noise_mean = 0 # Mean of the Gaussian noise adder\n",
    "noise_sd = 2 # Std.Dev of the Gaussian noise adder\n",
    "ridge_alpha = tuple([10**(x) for x in range(-3,0,1) ]) # Alpha (regularization strength) of ridge regression\n",
    "lasso_eps = 0.001\n",
    "lasso_nalpha=20\n",
    "lasso_iter=1000\n",
    "degree_min = 2\n",
    "degree_max = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feature and output vector following a non-linear function\n",
    "$$ The\\ ground\\ truth\\ or\\ originating\\ function\\ is\\ as\\ follows:\\  $$\n",
    "\n",
    "$$ y=f(x)= x^2sin(x)e^{-0.1x}+\\psi(x),$$\n",
    "$$ where $$\n",
    "$$ \\psi(x) = {\\displaystyle f(x\\;|\\;\\mu ,\\sigma ^{2})={\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}\\;e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_smooth = np.array(np.linspace(x_min,x_max,1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linearly spaced sample points\n",
    "X=np.array(np.linspace(x_min,x_max,N_points))\n",
    "\n",
    "# Samples drawn from uniform random distribution\n",
    "X_sample = x_min+np.random.rand(N_points)*(x_max-x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    result = x**2*np.sin(x)*np.exp(-(1/x_max)*x)\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_x = np.random.normal(loc=noise_mean,scale=noise_sd,size=N_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = func(X)+noise_x\n",
    "y_sampled = func(X_sample)+noise_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X,columns=['X'])\n",
    "df['Ideal y']=df['X'].apply(func)\n",
    "df['y']=y\n",
    "df['X_sampled']=X_sample\n",
    "df['y_sampled']=y_sampled\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the function(s), both the ideal characteristic and the observed output (with process and observation noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter('X','Ideal y',title='Ideal y',grid=True,edgecolors=(0,0,0),c='blue',s=40,figsize=(10,5))\n",
    "plt.plot(x_smooth,func(x_smooth),'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('X_sampled',y='y_sampled',title='Randomly sampled y',\n",
    "                grid=True,edgecolors=(0,0,0),c='orange',s=40,figsize=(10,5))\n",
    "plt.plot(x_smooth,func(x_smooth),'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('X',y='y',title='Linearly sampled y',grid=True,edgecolors=(0,0,0),c='orange',s=40,figsize=(10,5))\n",
    "plt.plot(x_smooth,func(x_smooth),'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import scikit-learn librares and prepare train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['X'], df['y'], test_size=0.33)\n",
    "X_train=X_train.values.reshape(-1,1)\n",
    "X_test=X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial model with Ridge regularization (pipelined) with lineary spaced samples\n",
    "** This is an advanced machine learning method which prevents over-fitting by penalizing high-valued coefficients i.e. keep them bounded **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linear_sample_score = []\n",
    "poly_degree = []\n",
    "for degree in range(degree_min,degree_max+1):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), RidgeCV(alphas=ridge_alpha,cv=5))\n",
    "    model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sample_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with randomly sampled data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['X_sampled'], df['y_sampled'], test_size=0.33)\n",
    "X_train=X_train.values.reshape(-1,1)\n",
    "X_test=X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_sample_score = []\n",
    "poly_degree = []\n",
    "for degree in range(degree_min,degree_max+1):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), RidgeCV(alphas=ridge_alpha,cv=5))\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(data={'degree':poly_degree,\n",
    "                              'Linear sample score':linear_sample_score,\n",
    "                              'Random sample score':random_sample_score})\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.plot(df_score['degree'],df_score['Linear sample score'],lw=2)\n",
    "plt.plot(df_score['degree'],df_score['Random sample score'],lw=2)\n",
    "plt.xlabel (\"Model Complexity: Degree of polynomial\",fontsize=20)\n",
    "plt.ylabel (\"Model Score: R^2 score on test set\",fontsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
