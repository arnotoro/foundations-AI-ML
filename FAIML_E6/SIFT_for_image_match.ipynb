{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Credits: https://github.com/Holmes-Alan/SIFT_ImgMatch/blob/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDSUBJsgnxlB"
      },
      "source": [
        "Load required library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udg6venZmc1o"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNwCp9n-n0dh"
      },
      "outputs": [],
      "source": [
        "# Resize images to a similar dimension\n",
        "# This helps improve accuracy and decreases unnecessarily high number of keypoints\n",
        "\n",
        "def imageResizeTrain(image):\n",
        "    maxD = 1024\n",
        "    height,width = image.shape\n",
        "    aspectRatio = width/height\n",
        "    if aspectRatio < 1:\n",
        "        newSize = (int(maxD*aspectRatio),maxD)\n",
        "    else:\n",
        "        newSize = (maxD,int(maxD/aspectRatio))\n",
        "    image = cv2.resize(image,newSize)\n",
        "    return image\n",
        "\n",
        "def imageResizeTest(image):\n",
        "    maxD = 1024\n",
        "    height,width,channel = image.shape\n",
        "    aspectRatio = width/height\n",
        "    if aspectRatio < 1:\n",
        "        newSize = (int(maxD*aspectRatio),maxD)\n",
        "    else:\n",
        "        newSize = (maxD,int(maxD/aspectRatio))\n",
        "    image = cv2.resize(image,newSize)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVElcgrUn6qJ"
      },
      "outputs": [],
      "source": [
        "# Define a list of images you want to test\n",
        "\n",
        "imageList = [\"book1.jpg\", \"book2.jpg\", \"eiffel.jpg\", \"superman.jpg\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm5aSMdAoTzp"
      },
      "outputs": [],
      "source": [
        "# We use grayscale images for generating keypoints\n",
        "imagesBW = []\n",
        "for imageName in imageList:\n",
        "    imagePath = str(imageName)\n",
        "    imagesBW.append(imageResizeTrain(cv2.imread(imagePath,0))) # flag 0 means grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crxTbxu0oiKZ"
      },
      "outputs": [],
      "source": [
        "# Using opencv's sift implementation here\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "def computeSIFT(image):\n",
        "    return sift.detectAndCompute(image, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI9Seeu3onVh",
        "outputId": "c03525ec-538f-42c1-a864-5e586a304d06"
      },
      "outputs": [],
      "source": [
        "keypoints = []\n",
        "descriptors = []\n",
        "for i,image in enumerate(imagesBW):\n",
        "    print(\"Starting for image: \" + imageList[i])\n",
        "    if imageList[i] == \"book1.jpg\":\n",
        "        print(\"  Skipping image: \" + imageList[i])\n",
        "    keypointTemp, descriptorTemp = computeSIFT(image)\n",
        "    keypoints.append(keypointTemp)\n",
        "    descriptors.append(descriptorTemp)\n",
        "    print(\"  Ending for image: \" + imageList[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aEQXhJ_ot2R"
      },
      "outputs": [],
      "source": [
        "for i, keypoint in enumerate(keypoints):\n",
        "    deserializedKeypoints = []\n",
        "    filepath = str(imageList[i].split('.')[0]) + \"_kps.txt\"\n",
        "    for point in keypoint:\n",
        "        temp = (point.pt, point.size, point.angle, point.response, point.octave, point.class_id)\n",
        "        deserializedKeypoints.append(temp)\n",
        "    with open(filepath, 'wb') as fp:\n",
        "        pickle.dump(deserializedKeypoints, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPCEAMqno2T5"
      },
      "outputs": [],
      "source": [
        "for i,descriptor in enumerate(descriptors):\n",
        "    filepath = str(imageList[i].split('.')[0]) + \"_feat.txt\"\n",
        "    with open(filepath, 'wb') as fp:\n",
        "        pickle.dump(descriptor, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Task 1:** Define a reasonable threshold for the similarity between two image-keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyp7zp5YrGqY"
      },
      "outputs": [],
      "source": [
        "threshold = 0.75\n",
        "def FilterMatches(matches, mode='selection'):\n",
        "    '''\n",
        "        Implements different options to filter matches.\n",
        "            - 'sort' will simply sort them by similarity distance.\n",
        "            - 'ratio' will employ the ratio test as in Lowe's paper\n",
        "    '''\n",
        "    if(mode == 'sort'):\n",
        "        selection = sorted(matches, key = lambda x:x[0].distance)\n",
        "    if(mode == 'ratio'):\n",
        "        selection = [[m] for m, n in matches if m.distance < threshold*n.distance]\n",
        "\n",
        "    return selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZmsMoUktBDb"
      },
      "source": [
        "Fetch Keypoints and Descriptors from stored files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWMZTSvZszCK"
      },
      "outputs": [],
      "source": [
        "def fetchKeypointFromFile(i):\n",
        "    filepath = str(imageList[i].split('.')[0]) + \"_kps.txt\"\n",
        "    keypoint = []\n",
        "    file = open(filepath,'rb')\n",
        "    deserializedKeypoints = pickle.load(file)\n",
        "    file.close()\n",
        "    for point in deserializedKeypoints:\n",
        "        temp = cv2.KeyPoint(\n",
        "            x=point[0][0],\n",
        "            y=point[0][1],\n",
        "            size=point[1],\n",
        "            angle=point[2],\n",
        "            response=point[3],\n",
        "            octave=point[4],\n",
        "            class_id=point[5]\n",
        "        )\n",
        "        keypoint.append(temp)\n",
        "    return keypoint\n",
        "\n",
        "def fetchDescriptorFromFile(i):\n",
        "    filepath = str(imageList[i].split('.')[0]) + \"_feat.txt\"\n",
        "    file = open(filepath,'rb')\n",
        "    descriptor = pickle.load(file)\n",
        "    file.close()\n",
        "    return descriptor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz6_7e8XtDKx"
      },
      "outputs": [],
      "source": [
        "# Calculate Results for any pair\n",
        "bf = cv2.BFMatcher()\n",
        "def calculateMatches(des1,des2):\n",
        "    matches = bf.knnMatch(des1,des2,k=2)\n",
        "    \"\"\"\n",
        "    for m,n in matches:\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            topResults1.append([m])\n",
        "    \"\"\"\n",
        "    topResults1 = FilterMatches(matches, mode='ratio')\n",
        "    matches = bf.knnMatch(des2,des1,k=2)\n",
        "    topResults2 = FilterMatches(matches, mode='ratio')\n",
        "    '''\n",
        "    for m,n in matches:\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            topResults2.append([m])\n",
        "    '''\n",
        "    topResults = []\n",
        "    for match1 in topResults1:\n",
        "        match1QueryIndex = match1[0].queryIdx\n",
        "        match1TrainIndex = match1[0].trainIdx\n",
        "\n",
        "        for match2 in topResults2:\n",
        "            match2QueryIndex = match2[0].queryIdx\n",
        "            match2TrainIndex = match2[0].trainIdx\n",
        "\n",
        "            if (match1QueryIndex == match2TrainIndex) and (match1TrainIndex == match2QueryIndex):\n",
        "                topResults.append(match1)\n",
        "    return topResults\n",
        "\n",
        "# scoring metric, a score greater than 10 means very good\n",
        "def calculateScore(matches,keypoint1,keypoint2):\n",
        "    return 100 * (matches/min(keypoint1,keypoint2))\n",
        "\n",
        "# draw KNN matching plot\n",
        "def getPlot(image1,image2,keypoint1,keypoint2,matches):\n",
        "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "    matchPlot = cv2.drawMatchesKnn(\n",
        "        image1,\n",
        "        keypoint1,\n",
        "        image2,\n",
        "        keypoint2,\n",
        "        matches,\n",
        "        None,\n",
        "        matchColor=[255, 0, 0],\n",
        "        singlePointColor=[0, 255, 0],\n",
        "        flags=0\n",
        "    )\n",
        "    return matchPlot\n",
        "\n",
        "def getPlotFor(i,j,keypoint1,keypoint2,matches):\n",
        "    image1 = imageResizeTest(cv2.imread(imageList[i]))\n",
        "    image2 = imageResizeTest(cv2.imread(imageList[j]))\n",
        "    return getPlot(image1,image2,keypoint1,keypoint2,matches)\n",
        "\n",
        "# calculate matching results for any two images\n",
        "def calculateResultsFor(i,j):\n",
        "    keypoint1 = fetchKeypointFromFile(i)\n",
        "    descriptor1 = fetchDescriptorFromFile(i)\n",
        "    keypoint2 = fetchKeypointFromFile(j)\n",
        "    descriptor2 = fetchDescriptorFromFile(j)\n",
        "    matches = calculateMatches(descriptor1, descriptor2)\n",
        "    score = calculateScore(len(matches),len(keypoint1),len(keypoint2))\n",
        "    plot = getPlotFor(i,j,keypoint1,keypoint2,matches)\n",
        "    print(f\"Match paires: {len(matches)}, Keypoints in img1: {len(keypoint1)}, Keypoints in img2: {len(keypoint2)}\")\n",
        "    print(f\"Matching score is: {score}%\")\n",
        "    plt.imshow(plot),plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate the SIFT matches between images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "X3P3_YAPuEVZ",
        "outputId": "7dc58f55-159f-46ae-8b38-4c2a98474b9c"
      },
      "outputs": [],
      "source": [
        "calculateResultsFor(0, 3) # calculate results for image 1 and image 4 (book1 and superman)\n",
        "# Add tests between each image pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Task 2:** Redo the SIFT with all the images (including the 'book1_masked')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPiQ6gQx6V/4HstixxIFUwU",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
